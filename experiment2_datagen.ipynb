{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3215156f-6c05-4b90-98dd-ba14899bef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mrmprocs: process 1 not removed\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Distributed /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Distributed/src/cluster.jl:1041\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the script in parallel\n",
    "using Distributed\n",
    "\n",
    "# Add processes\n",
    "rmprocs(workers()) # This will remove all worker processes\n",
    "addprocs(0) # Change this to the number of cores you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63063747-6eb3-43e7-8111-28392e672c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/github/DifferentiableUserModels-JT/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "@everywhere begin\n",
    "    using Pkg\n",
    "    Pkg.activate(\".\")\n",
    "    Pkg.instantiate()\n",
    "    #Pkg.status()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f3afe3-8f12-4a51-894d-d4fcfde3ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    using ArgParse\n",
    "    using BSON\n",
    "    using Distributions\n",
    "    using Flux\n",
    "    using Stheno\n",
    "    using Tracker\n",
    "    using Printf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d71ffe6-c800-4fe7-9134-882ff1ce862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mReplacing docs for `Main.NeuralProcesses.Categorical :: Union{}` in module `Main.NeuralProcesses`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base.Docs docs/Docs.jl:240\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@everywhere include(joinpath(@__DIR__, \"NeuralProcesses.jl/src/NeuralProcesses.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d340148-c756-4ce6-aa60-a10856516757",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using .NeuralProcesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84537e7-d05d-4a82-8ce4-49e70b353218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@everywhere begin\n",
    "    #include(joinpath(@__DIR__, \"NeuralProcesses.jl/src/NeuralProcesses.jl\"))\n",
    "    #include(\"NeuralProcesses.jl/src/NeuralProcesses.jl\")    \n",
    "    #using .NeuralProcesses\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3251e1-f348-4263-97d6-a73223f1b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = ArgParseSettings()\n",
    "# @add_arg_table! parser begin\n",
    "#     \"--gen\"\n",
    "#         help = \"Experiment setting: gridworld, menu_search, h_menu_search\"\n",
    "#         arg_type = String\n",
    "#         default = \"menu_search\"\n",
    "#     \"--n_traj\"\n",
    "#         help = \"Number of context trajectories. Setting to 0 randomizes between 1 and 8.\"\n",
    "#         arg_type = Int\n",
    "#         default = 0\n",
    "#     \"--n_epochs\"\n",
    "#         help = \"Number of training epochs.\"\n",
    "#         arg_type = Int\n",
    "#         default = 50\n",
    "#     \"--n_batches\"\n",
    "#         help = \"Number of batches.\"\n",
    "#         arg_type = Int\n",
    "#         default = 25\n",
    "#     \"--batch_size\"\n",
    "#         help = \"Batch size.\"\n",
    "#         arg_type = Int\n",
    "#         default = 4\n",
    "#     \"--params\"\n",
    "#         help = \"Return params?\"\n",
    "#         arg_type = Bool\n",
    "#         default = false\n",
    "#     \"--p_bias\"\n",
    "#         help = \"Probability of generating a sample with biased model\"\n",
    "#         arg_type = Float64\n",
    "#         default = 0.0\n",
    "#     \"--bson\"\n",
    "#         help = \"Directly specify the file to save the model to and load it from.\"\n",
    "#         arg_type = String\n",
    "#     \"--epsilon\"\n",
    "#         help = \"Value for epsilon.\"\n",
    "#         arg_type = Float64\n",
    "# end\n",
    "# args = parse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4855248-26f0-41dd-ad0e-3ecad93967c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary to just use the default arguments from the argument parser\n",
    "@everywhere begin\n",
    "    function get_default_args()\n",
    "        defaults = Dict(\n",
    "            \"gen\" => \"menu_search\",\n",
    "            \"n_traj\" => 0,\n",
    "            \"n_epochs\" => 50,\n",
    "            \"n_batches\" => 25,\n",
    "            \"batch_size\" => 4,\n",
    "            \"params\" => false,\n",
    "            \"p_bias\" => 0.0,\n",
    "            \"bson\" => \"\",\n",
    "            \"epsilon\" => 0.0\n",
    "        )\n",
    "        return defaults\n",
    "    end\n",
    "    \n",
    "    args = get_default_args()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e459a34-1815-4129-9068-c84d78ca0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother initializing the model\n",
    "# println(\"Initializing model...\")\n",
    "\n",
    "# model = anp_ex2(\n",
    "#     dim_embedding=128,\n",
    "#     num_encoder_heads=8,\n",
    "#     num_encoder_layers=6,\n",
    "#     num_decoder_layers=6,\n",
    "#     args=args\n",
    "# ) |> gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94735e4c-93cc-4ce1-bb2d-830288291217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother initializing the loss\n",
    "# println(\"Initializing loss...\")\n",
    "\n",
    "# loss(xs...) = np_elbo(\n",
    "#     xs...,\n",
    "#     num_samples=5,\n",
    "#     fixed_σ_epochs=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ecbf38-829d-4cc3-ad23-5f97e0b7c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data generator\n",
      "Data gen initialized\n"
     ]
    }
   ],
   "source": [
    "# Make the data generator\n",
    "@everywhere begin\n",
    "    println(\"Initializing data generator\")\n",
    "    \n",
    "    batch_size  = args[\"batch_size\"]\n",
    "    \n",
    "    # Redundant. Required to fit the DataGenerator definition\n",
    "    x_context = Distributions.Uniform(-2, 2)\n",
    "    x_target  = Distributions.Uniform(-2, 2)\n",
    "    \n",
    "    num_context = Distributions.DiscreteUniform(10, 10)\n",
    "    num_target  = Distributions.DiscreteUniform(10, 10)\n",
    "    \n",
    "    data_gen = NeuralProcesses.DataGenerator(\n",
    "                    SearchEnvSampler(args;),\n",
    "                    batch_size=batch_size,\n",
    "                    x_context=x_context,\n",
    "                    x_target=x_target,\n",
    "                    num_context=num_context,\n",
    "                    num_target=num_target,\n",
    "                    σ²=1e-8\n",
    "                )\n",
    "    println(\"Data gen initialized\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a541d13-6eed-464d-9e16-01725b9aff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:           4     \n",
      "Number of batches     25    \n"
     ]
    }
   ],
   "source": [
    "@everywhere begin\n",
    "    # Variables normally defined in the part where you train the model\n",
    "    #tasks_per_epoch=2^5\n",
    "    #total_epochs = total_epochs=args[\"n_epochs\"]\n",
    "    #starting_epoch=0\n",
    "    batches=args[\"n_batches\"]\n",
    "    experiment = \"menu_search\"\n",
    "    \n",
    "    # Divide out batch size to get the number of batches per epoch.\n",
    "    #batches_per_epoch = div(tasks_per_epoch, data_gen.batch_size)\n",
    "    \n",
    "    # Display the settings of the training run.\n",
    "    #@printf(\"Epochs:               %-6d\\n\", total_epochs)\n",
    "    #@printf(\"Starting epoch:       %-6d\\n\", starting_epoch)\n",
    "    #@printf(\"Tasks per epoch:      %-6d\\n\", batches_per_epoch * data_gen.batch_size)\n",
    "    @printf(\"Batch size:           %-6d\\n\", data_gen.batch_size)\n",
    "    @printf(\"Number of batches     %-6d\\n\", batches)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e0bd2-89b3-4885-9ead-bf30ae4b47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the data generator\n",
    "# for batch_n in 1:batches-1\n",
    "#     # Warmup epoch\n",
    "#     if batch_n == starting_epoch\n",
    "#         n_mini_batches = 1\n",
    "#     else\n",
    "#         n_mini_batches = batches_per_epoch\n",
    "#     end\n",
    "#     # Generate data\n",
    "#     data = gen_batch(data_gen, n_mini_batches; eval=false)\n",
    "\n",
    "#     if experiment == \"menu_search\"\n",
    "#         BSON.bson(\"data/ex2/\"*string(batch_n)*\".bson\", data=data)\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e28f6-fd5d-4ed4-bb18-2e755a99f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@distributed for batch_n in 1:batches-1\n",
    "#for batch_n in 1:batches-1\n",
    "    @printf(\"Running batch:               %-6d\\n\", batch_n)\n",
    "    # Warmup epoch\n",
    "    if batch_n == starting_epoch\n",
    "        n_mini_batches = 1\n",
    "    else\n",
    "        n_mini_batches = batches_per_epoch\n",
    "    end\n",
    "    # Generate data\n",
    "    data = gen_batch(data_gen, n_mini_batches; eval=false)\n",
    "\n",
    "    if experiment == \"menu_search\"\n",
    "        filename = \"data/ex2/\"*string(batch_n)*\".bson\"\n",
    "        # If the file doesn't exist, create it\n",
    "        if !isfile(filename)\n",
    "            open(filename, \"w\") do f\n",
    "            end\n",
    "            # File is now created\n",
    "        end\n",
    "        # Save data to the file\n",
    "        BSON.bson(filename, data=data)\n",
    "        @printf(\"Finished batch:               %-6d\\n\", batch_n)\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e4279f6-8264-4604-9207-7c75596d062e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = gen_batch(data_gen, 3; eval=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3dea8eb-484a-4bc0-8664-6e5f647e4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc,yc,xt,yt = data[2];\n",
    "size(xt);\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69607f72-0d84-4d34-9bd5-6e835b74654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_context = rand(Distributions.DiscreteUniform(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c1894f-365c-433e-89fd-a07fe7d2065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_hdf5 (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using HDF5\n",
    "# Add multiple pieces of metadata to the dataset\n",
    "\n",
    "metadata = Dict(\n",
    "\"gen_type\" => \"SearchEnvSampler / menu_search\",\n",
    "\"eval\" => false,\n",
    "\"batch_size\" => batch_size,\n",
    "\"n_minibatches\" => n_minibatches,\n",
    "\"n_traj\" => \"random(1-8)\" #This is what happens when it's set to 0 in args dictionary\n",
    "\"noise_variance\" => 1e-8,\n",
    "\"p_bias\" => args[\"p_bias\"]\n",
    "\"epsilon\" => args[\"epsilon\"]\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "function create_hdf5_ex2(data, filename, batch_size, metadata)\n",
    "    # Open the HDF5 file for writing, overwriting if it exists\n",
    "    h5open(filename, \"w\") do fid\n",
    "        # Loop over the data vector\n",
    "        for (i, d) in enumerate(data)\n",
    "            # Create a group for each mini-batch\n",
    "            g = create_group(fid, \"mini_batch_$i\")\n",
    "\n",
    "            # Add datasets to the group\n",
    "            g[\"xc\"] = d[1]\n",
    "            g[\"yc\"] = d[2]\n",
    "            g[\"xt\"] = d[3]\n",
    "            g[\"yt\"] = d[4]\n",
    "\n",
    "            # Add metadata to the group\n",
    "            for (key, value) in metadata\n",
    "                write_attribute(g, key, value)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "282f7aec-bb82-4877-b638-08fd7c41cf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscreteUniform(a=10, b=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_gen.num_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7cec306-f83a-4c85-a1e4-922cb1a7ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/ex2/batch1.hdf\"\n",
    "create_hdf5(data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4ab61-4851-4579-a98a-71fec00a4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother training the model\n",
    "# println(\"Proceeding to training loop...\")\n",
    "\n",
    "# mkpath(\"models/\"*string(args[\"bson\"]))\n",
    "\n",
    "# train_model!(\n",
    "#         model,\n",
    "#         loss,\n",
    "#         data_gen,\n",
    "#         ADAM(5e-4),\n",
    "#         bson=args[\"bson\"],\n",
    "# \texperiment=args[\"gen\"],\n",
    "#         starting_epoch=0,\n",
    "#         tasks_per_epoch=2^5,\n",
    "#         batches=args[\"n_batches\"],\n",
    "# \ttotal_epochs=args[\"n_epochs\"],\n",
    "#         epsilon=args[\"epsilon\"]\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
